<!DOCTYPE html>
<html>
    <head>
        <title>Adversarial Vocoding</title>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
        <style type="text/css">
            table, th, td {
              border: 1px solid black;
            }
            td {width: 250px;}
            /*audio { width: 400px; }*/
            .divexamples {padding-bottom: 30px;}
            .class_audio {width: 250px;}
        </style>
    </head>
    <body>
        <h1>Expediting TTS Synthesis with Adversarial Vocoding</h1>
        <h3><a href="https://paarthneekhara.github.io">*Paarth Neekhara</a>, <a href="https://chrisdonahue.github.io">*Chris Donahue</a>, <a href="http://msp.ucsd.edu">Miller Puckette</a>, <a href="http://dub.ucsd.edu">Shlomo Dubnov</a>, <a href="http://cseweb.ucsd.edu/~jmcauley/">Julian McAuley</a> </h3>
        <p style="width: 80%">
	We present sound examples for the experiments in our paper <i>Expediting TTS Synthesis with Adversarial Vocoding</i> (<a href="https://arxiv.org/abs/1904.07944">paper</a>, <a href="https://github.com/paarthneekhara/advoc">code</a>). Sound files on this page were synthesized by vocoding mel spectrograms using various methods including our own. These mel spectrograms were extracted either from real waveforms (from the <a href="https://keithito.com/LJ-Speech-Dataset/">LJ Speech Dataset</a>) or synthesized by a state-of-the-art TTS system (<a href="https://arxiv.org/abs/1712.05884">Tacotron-2</a>).
        </p>

        <div class = "divexamples" id = "Inversion">
		<h2>(Table 1) Examining the effects of magnitude and phase estimation heuristics</h2>
		<p style="width: 80%">These examples correspond to Table 1 from our paper. Here we are examining the effects of common techniques used in heuristic-based vocoding of mel spectrograms. Specifically, we mix and match different heuristics for performing <i>magnitude estimation</i> (converting log-frequency mel spectrograms into linear-frequency magnitude spectrograms) and <i>phase estimation</i> (estimating phase for the magnitude spectrogram). Each row in this table is labeled with the two methods used for both estimation problems (e.g. "Mel pseudoinverse + Griffin-Lim" uses the pseudoinverse of the mel basis to perform magnitude estimation, and Griffin-Lim to reconstruct phase for this estimated magnitude).</p>
		<p style="width: 80%">We observe that coupling an ideal solution (using real data as as proxy) to one subproblem with a reasonable heuristic for the other ("Real mag + LWS" and "Mel pseudoinverse + Real phase") results in reasonable speech. Of the two, we target magnitude estimation in this work and use Local Weighted Sums (<a href="https://pypi.org/project/lws/">LWS</a>) as a phase estimator. Hence, "Real Mag + LWS" represents the upper bound on quality that our method hopes to achieve.</p>
            <table id = "InversionTable">
              <tr class = "theader">
              </tr>
            </table>
        </div>

        <div class = "divexamples" id = "Real">
            <h2>(Table 2 MOS-Real) Vocoding real mel spectrograms</h2>
	    <p style="width: 80%">These examples correspond to Table 2 (column MOS-Real) from our paper. Here we take waveforms from the real LJ Speech dataset and extract mel spectrograms. We then vocode these mel spectrograms back to audio using various methods. We do this to compare the quality of vocodings without the additional confounding factor of using synthetic spectrograms. We note that our methods (AdVoc and AdVoc-small) are significantly higher quality than the pseudoinverse heuristic and hundreds of times faster than the autoregressive WaveNet vocoder.</p>
            <table id = "realTable">
              <tr class = "theader">
              </tr>
            </table>
        </div>

        <div class = "divexamples" id = "TTS">
		<h2>(Table 2 MOS-TTS) Vocoding synthetic spectrograms</h2>
		<p style="width: 80%">These examples correspond to Table 2 (column MOS-TTS) from our paper. Here we use <a href="https://arxiv.org/abs/1712.05884">Tacotron-2</a> to generate synthetic spectrograms corresponding to a real transcript. We then vocode these synthetic spectrograms to waveforms using various methods. This represents a realistic TTS setting used in state-of-the-art systems. Again our methods outperform the pseudoinverse heuristic.</p>
            <table id = "TTSTable">
              <tr class = "theader">
              </tr>
            </table>
        </div>
        
        <div class = "divexamples" id = "Jokes">
            <h2>Vocdoing-based TTS on out-of-domain transcriptions</h2>
	    <p style="width: 80%">Here we show vocodings of various methods on synthetic spectrograms generated by Tacotron-2. This is intended to demonstrate that these systems can produce reasonable audio for transcripts that are outside of LJ Speech (as we train both Tacotron-2 <i>and</i> AdVoc on this dataset).</p>
            <table id = "JokesTable">
              <tr class = "theader">
              </tr>
            </table>
        </div>

        <div class="divexamples" id = "sc09">
            <h2>(Table 3) Unsupervised generation of small-vocabulary speech</h2>
	    <p style="width: 80%">
	    Here we are concerned with <i>unsupervised</i> generation of speech (as opposed to supervised as in TTS). The goal here is to train a system which can learn to speak coherent English words <i>without</i> labels. Specifically, we wish to generate spoken digits (i.e. 10 words "zero" through "nine"). Our <a href="https://arxiv.org/abs/1802.04208">previous work</a> attempts to do this directly in the waveform domain (WaveGAN) and also in a naive spectrogram domain combined with Griffin-Lim for heuristic inversion (SpecGAN). Here we show that we can get substantially higher-quality results by first training a GAN to generate mel spectrograms (MelSpecGAN) and then training an adversarial vocoder to vocode those spectrograms into audio.</p>
            <!-- When trained on this dataset <i>without</i> label conditioning, our WaveGAN and SpecGAN models learn to generate coherent words. Results are arranged into numerical ordering by post-hoc labeling of random examples by the classifier discussed in the paper. -->
            <ul>

                <li>
                <span class="desc">
                  Real data
                </span>
                <div class="example">
                  <audio controls>
                  <source src="audio/SC09/real.wav" type="audio/wav">
                  Your browser does not support the audio tag.
                </audio>
                </div>
                </li>


                <li>
                <span class="desc">
                  <a href="https://arxiv.org/abs/1802.04208">WaveGAN</a>
                </span>
                <div class="example">
                  <audio controls>
                  <source src="audio/SC09/wavegan.wav" type="audio/wav">
                  Your browser does not support the audio tag.
                </audio>
                </div>
                </li>


                <li>
                <span class="desc">
                  <a href="https://arxiv.org/abs/1802.04208">SpecGAN + Griffin-Lim</a>
                </span>
                <div class="example">
                  <audio controls>
                  <source src="audio/SC09/specgan_gl.wav" type="audio/wav">
                  Your browser does not support the audio tag.
                </audio>
                </div>
                </li>

                <li>
                <span class="desc">
                  
                  <b>MelSpecGAN + AdVoc</b>

                </span>
                <div class="example">
                  <audio controls>
                  <source src="audio/SC09/specgan_advoc.wav" type="audio/wav">
                  Your browser does not support the audio tag.
                </audio>
                </div>
                </li>

            </ul>
        </div>


    </body>

    <script type="text/javascript">
        function fillTable(table_id, subFolder, methods, method_names, transcripts){
            var audio_html_pre = '<audio class="class_audio" controls><source src="'
            var audio_html_post = '" type="audio/wav">Your browser does not support the audio tag</audio>'
            $(table_id).find('.theader').append("<th>Method</th>");
            for(var j = 0; j < 4; j++){
                $(table_id).find('.theader').append("<th> Audio " + (j + 1) + "</th>");
            }
            if(transcripts.length > 0){
                var trow = "<tr>"
                trow += "<td></td>";
                for(var ti = 0; ti < transcripts.length; ti++){
                    trow += "<td>" + transcripts[ti] + "</td>";
                }
                trow += "</tr>"
               $(table_id).find('tbody').append( trow ); 
            }
            for(var i = 0; i < methods.length; i++){

                var trow = "<tr>"
                trow += "<td style='word-wrap: break-word; width : 200px;'>" +  method_names[i] + "</td>"
                for(var j = 0; j < 4; j++){
                    trow += "<td>"+ audio_html_pre + subFolder + "/" + methods[i] + "/" + (j+1) + ".wav" +audio_html_post +  "</td>";    
                }
                trow += "</tr>"
                $(table_id).find('tbody').append( trow );
            }
        }

        var tts_texts = [
            "The Service should consider preparing formal explanations of the cooperation anticipated during a Presidential visit to a city",
            "and reports from other agencies which independently evaluate their information for potential sources of danger.",
            "These substitute measures were of limited value. Agent Lawson was unable to state whether he had actually instructed",
            "this Commission has necessarily examined into the functioning of the various Federal agencies concerned with the tragic trip of President Kennedy to Dallas",
        ]

        var jokes_texts = [
            "Have you heard about the corduroy pillow? No? Really? It’s making headlines!",
            "Why do chicken coups always have two doors? With four, they'd be chicken sedans.",
            "What did one shark say to the other as he ate a clownfish? Well this tastes a little funny.",
            "Why wouldn’t the shrimp share his treasure? Because he was a little shellfish."
        ]



        fillTable('#realTable', 
            'audio/Real', 
            ['Real', 'Pinv', 'Wavenet', 'Waveglow', 'Advoc', 'Advoc_small'],
            ['Real data', 'Psuedoinv', '<a href="https://arxiv.org/abs/1609.03499">WaveNet</a>', '<a href="https://arxiv.org/abs/1811.00002">WaveGlow</a>',  '<b>AdVoc</b>', '<b>AdVoc-small</b>'],
            tts_texts
            )

        fillTable('#TTSTable', 
            'audio/TTS', 
            ['Real', 'Pinv', 'Wavenet', 'Waveglow', 'Advoc', 'Advoc_small'],
            ['Real data', 'Psuedoinv', '<a href="https://arxiv.org/abs/1609.03499">WaveNet</a>', '<a href="https://arxiv.org/abs/1811.00002">WaveGlow</a>',  '<b>AdVoc</b>', '<b>AdVoc-small</b>'],
            tts_texts
            )

        // fillTable('#JokesTable', 
        //     'audio/Jokes', 
        //     ['Pinv', 'Advoc', 'Advoc_small', 'Wavenet', 'Waveglow'],
        //     ['Pinv', 'Advoc', 'Advoc_small', 'Wavenet', 'Waveglow'],
        //     jokes_texts
        //     )

       
        
        fillTable('#InversionTable', 
            'audio/Inversion', 
            ['Real', 'Mag_GL', 'Mag_LWS', 'Mel_Phase', 'Mel_GL', 'Mel_LWS'],
            ['Real mag + Real phase (Original)', 'Real mag + Griffin-Lim', 'Real mag + LWS', 'Mel psuedoinverse + Real phase', 'Mel psuedoinverse + Griffin-Lim', 'Mel psuedoinverse + LWS'],
            tts_texts
            )

         fillTable('#JokesTable', 
            'audio/Jokes', 
            ['Pinv', 'Wavenet', 'Waveglow', 'Advoc', 'Advoc_small'],
            ['Psuedoinv', '<a href="https://arxiv.org/abs/1609.03499">WaveNet</a>', '<a href="https://arxiv.org/abs/1811.00002">WaveGlow</a>',  '<b>AdVoc</b>', '<b>AdVoc-small</b>'],
            jokes_texts
            )

    </script>

</html>

